# Multi-Sine Wave Benchmark: Complete Analysis

> **300 Combinations**: 6 Training Modes Ã— 10 Numerical Types Ã— 5 Layer Types  
> **Task**: Real-time sine wave frequency adaptation with continuous inference

## Overview

This benchmark tests Loom's training algorithms on a challenging real-time task: adapting to changing sine wave frequencies while maintaining continuous inference availability. The frequency switches every 2.5 seconds (1x â†’ 2x â†’ 3x â†’ 4x), and models must adapt quickly while still producing predictions.

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘   LAYERS: Dense, Conv2D, RNN, LSTM, Attention (5 types)                                      â•‘
â•‘   MODES:  NormalBP, StepBP, Tween, TweenChain, StepTween, StepTweenChain (6 modes)          â•‘
â•‘   TYPES:  int8-int64, uint8-uint64, float32, float64 (10 types)                             â•‘
â•‘   TOTAL:  6 Ã— 10 Ã— 5 = 300 combinations                                                      â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

---

## ğŸ† Key Findings

### Absolute Best Configuration

| Metric | Value |
|--------|-------|
| **Mode** | StepTweenChain |
| **Layer** | Conv2D |
| **Type** | float32 |
| **Score** | 1187 |
| **Accuracy** | 98.7% |
| **Throughput** | 120,255/sec |
| **Availability** | 100.0% |

### Why Conv2D Wins

Conv2D with its 2x2 kernel acts as a **pattern detector** across adjacent time steps in the sliding window input. For sine wave prediction, this captures local curve shapes (slopes, inflection points) more effectively than Dense layers treating all inputs equally.

### Why StepTweenChain Wins

StepTweenChain provides:
- **100% availability**: Never blocks for batch training
- **Immediate learning**: Trains on every sample
- **Chain rule accuracy**: Proper gradient propagation

---

## ğŸ’¡ The Core Thesis

> **Backprop optimizes correctness. StepTweenChain optimizes existence.**  
> **Real-time systems need both â€” and the ability to move between them.**

### Learning is Not a Single Problem

Most AI discourse assumes:
- Offline training
- Frozen deployment
- No hard latency constraints
- No requirement for perpetual availability

**This benchmark breaks that assumption.**

What these results empirically demonstrate:
- No single method dominates across **availability, latency, throughput, accuracy, and recovery**
- The *best system* is not a better optimizer â€” it's a **policy over optimizers**

**A learning system without a spectrum is forced to solve every phase of learning with the wrong tool.**

---

## ğŸ”§ The Role of Each Training Mode

These aren't "variants" of backprop. They're **distinct roles** that a real-time learning system needs:

### ğŸ”¹ NormalBP (Backpropagation)

| Aspect | Details |
|--------|---------|
| **Role** | Convergence + Correctness |
| **Strength** | Once the signal stabilizes, it locks onto the right basin |
| **Weakness** | Blocks inference, stalls real-time systems |
| **Availability** | ~30-50% (blocked during batch training) |
| **Use When** | You *can afford* to pause the world |

**Best for**: Offline training, batch processing, when accuracy is the only metric.

```
âš ï¸ NormalBP achieves 98%+ accuracy but only 49% availability
   â†’ Half the time, your system can't respond to inputs
```

---

### ğŸ”¹ StepBP (Step-Based Backprop)

| Aspect | Details |
|--------|---------|
| **Role** | Controlled Progression |
| **Strength** | Keeps training moving without catastrophic blocking |
| **Weakness** | Still assumes gradient reliability |
| **Availability** | 100% |
| **Use When** | Signal exists but timing matters |

**Best for**: When you need gradients but can't afford full batch pauses.

---

### ğŸ”¹ Tween (Neural Tweening)

| Aspect | Details |
|--------|---------|
| **Role** | *Existence under zero signal* |
| **Strength** | Best-effort motion when gradients are meaningless |
| **Weakness** | Not precise, not stable long-term |
| **Availability** | ~60% |
| **Use When** | **Everything is 0% accuracy but the system must stay alive** |

**This is the key one people underestimate.**

Tween keeps the network moving toward targets even when:
- Gradients are vanishing
- Loss landscape is flat
- Traditional training would stall completely

```
ğŸ’¡ Tween is NOT about being accurate.
   Tween is about NOT DYING when accuracy is impossible.
```

---

### ğŸ”¹ TweenChain (Tween with Chain Rule)

| Aspect | Details |
|--------|---------|
| **Role** | Temporal Depth Alignment |
| **Strength** | Handles deeper networks by interpolating across time, not layers |
| **Weakness** | Can still block during batch processing |
| **Availability** | ~60% |
| **Use When** | Depth + time both matter |

**Best for**: Deep networks where layer-by-layer tweening loses coherence.

---

### ğŸ”¹ StepTween (Step + Tween)

| Aspect | Details |
|--------|---------|
| **Role** | Availability-First Learning |
| **Strength** | Zero blocking, massive throughput, immediate response |
| **Weakness** | Slight accuracy tradeoff in some cases |
| **Availability** | 100% |
| **Use When** | **The system must always respond** |

**Best for**: Real-time inference systems that need continuous learning.

---

### ğŸ”¹ StepTweenChain (Step + Tween + Chain Rule)

| Aspect | Details |
|--------|---------|
| **Role** | **Unified Real-Time Learning Regime** |
| **Strength** | ~100% availability, near-BP accuracy, highest throughput, zero blocking |
| **Weakness** | Requires more complex state management |
| **Availability** | 100% |
| **Use When** | The system *lives in the world* |

**This is why it wins overall.**

```
StepTweenChain = The mode for systems that cannot afford to stop.

Robotics, real-time control, live adaptation, always-on AI.
```

---

## ğŸ¯ When to Use Each Mode

### Decision Matrix

| Scenario | Recommended Mode | Why |
|----------|------------------|-----|
| **Offline batch training** | NormalBP | Maximum accuracy, time doesn't matter |
| **Fine-tuning with deadline** | StepBP | Gradient-based but non-blocking |
| **Catastrophic signal loss** | Tween | Keeps weights moving when gradients fail |
| **Deep network real-time** | TweenChain | Handles depth with temporal coherence |
| **Always-on inference + learning** | StepTween | Never blocks, always responds |
| **Production real-time AI** | **StepTweenChain** | Best overall for living systems |

### The Spectrum in Action

```
Situation: Real-time robot arm tracking a moving target

1. Target acquired, stable signal â†’ StepTweenChain (learn + respond)
2. Target occluded, signal lost â†’ Tween (survive, don't stall)
3. Target reacquired â†’ StepTweenChain (resume learning)
4. Periodic maintenance window â†’ NormalBP (deep refinement)

A single learning rule cannot handle this.
The robot needs a POLICY over learning modes.
```

---

## ğŸ”¬ Why Conv2D + StepTweenChain Wins

> *"Conv2D probably wins because it best captures frames of time and can better tween between them"*

Yes â€” and more precisely:

| Component | Role |
|-----------|------|
| **Conv2D** | Encodes **spatial continuity** â€” pattern detection across time windows |
| **StepTweenChain** | Encodes **temporal continuity** â€” smooth interpolation through time |
| **float32** | Hits the **numerical sweet spot** for SIMD, cache efficiency, noise tolerance |

### What You've Actually Built: A Spatiotemporal Interpolator

The combination of Conv2D + StepTweenChain isn't just "good" â€” it's a **spatiotemporal interpolator with adaptive correction**:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        SPATIOTEMPORAL INTERPOLATOR                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                    â”‚
â”‚   INPUT: [sin(t-15), sin(t-14), ..., sin(t)]  â† 16-sample sliding window         â”‚
â”‚                           â”‚                                                        â”‚
â”‚                           â–¼                                                        â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                     â”‚
â”‚   â”‚         CONV2D (4Ã—4 kernel)             â”‚  â† SPATIAL: detects local patterns â”‚
â”‚   â”‚   â€¢ Captures curve shapes               â”‚     (slopes, peaks, inflections)   â”‚
â”‚   â”‚   â€¢ Encodes position-relative features  â”‚                                     â”‚
â”‚   â”‚   â€¢ Translation-invariant detection     â”‚                                     â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                     â”‚
â”‚                           â”‚                                                        â”‚
â”‚                           â–¼                                                        â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                     â”‚
â”‚   â”‚       STEPTWEENCHAIN TRAINING           â”‚  â† TEMPORAL: smooth weight updates â”‚
â”‚   â”‚   â€¢ Interpolates toward targets         â”‚     (no discontinuities)           â”‚
â”‚   â”‚   â€¢ Chain rule preserves gradients      â”‚                                     â”‚
â”‚   â”‚   â€¢ Never blocks (100% availability)    â”‚                                     â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                     â”‚
â”‚                           â”‚                                                        â”‚
â”‚                           â–¼                                                        â”‚
â”‚   OUTPUT: sin(t+1)  â† Prediction with adaptive correction                        â”‚
â”‚                                                                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Breaking Down the Math

| Component | Mathematical Role | Why It Matters |
|-----------|-------------------|----------------|
| **Conv2D spatial** | `f(x) = Î£ w[i,j] Â· x[i,j]` | Detects **where** patterns occur in the window |
| **StepTween temporal** | `w[t+1] = w[t] + Î±(target - current)` | Smoothly **interpolates** weights toward targets |
| **Chain rule correction** | `âˆ‚L/âˆ‚w = âˆ‚L/âˆ‚y Â· âˆ‚y/âˆ‚w` | **Corrects** interpolation with gradient information |
| **float32 precision** | 32-bit IEEE 754 | Balances accuracy vs speed for SIMD ops |

### Why This Emerges Naturally

The architecture isn't accidental â€” it's **inevitable** given the constraints:

1. **Real-time demands availability** â†’ Must use step-based (non-blocking)
2. **Continuous signal demands smoothness** â†’ Must interpolate, not jump
3. **Prediction demands pattern detection** â†’ Must use spatial kernels (Conv)
4. **Accuracy demands correction** â†’ Must include chain rule gradients

**Result**: A neural network that acts like a **Kalman filter meets video codec**:
- Predicts the next frame (spatial patterns)
- Smoothly updates its model (temporal interpolation)
- Corrects errors when they occur (adaptive feedback)
- Never stalls while doing so (real-time capable)

---

## ğŸš« What This Benchmark Does NOT Claim

This is important to be clear about:

| âŒ NOT Claiming | âœ… Actually Claiming |
|-----------------|---------------------|
| "StepTweenChain beats backprop" | StepTweenChain wins on **real-time metrics** |
| "Backprop is wrong" | Backprop is insufficient **alone** for real-time |
| "One mode is universally best" | Different modes serve different **operating conditions** |
| "This replaces gradient descent" | This **complements** gradient descent with alternatives |

The thesis is:

> **Static training â‰  Real-time learning**  
> **Batch convergence â‰  Continuous adaptation**  
> **Accuracy â‰  Availability**

You didn't "beat backprop". You showed **why backprop alone is insufficient** for systems that must exist in the world.

---

## Summary by Layer Type

### Accuracy Across All Types (%)

| Layer | Mode | int8 | int16 | int32 | int64 | uint8 | uint16 | uint32 | uint64 | float32 | float64 | Avg |
|-------|------|------|-------|-------|-------|-------|--------|--------|--------|---------|---------|-----|
| **Dense** | NormalBP | 13 | 20 | 20 | 21 | 13 | 23 | 21 | 13 | **99** | **99** | 34 |
| **Conv2D** | StepTweenChain | 13 | 20 | 22 | 22 | 13 | 21 | 21 | 22 | **99** | 21 | 27 |
| **RNN** | StepTween | 13 | 21 | 23 | 22 | 13 | 23 | 21 | 23 | **77** | 21 | 26 |
| **LSTM** | NormalBP | 13 | 20 | 21 | 21 | 13 | 23 | 21 | 13 | 54 | **59** | 26 |
| **Attention** | StepTween | 13 | 20 | 21 | 21 | 13 | 22 | 21 | 21 | **90** | 21 | 26 |

> **Note**: Integer types (int8-uint64) perform poorly (~13-23%) because sine wave values scaled to integers lose precision. Float32 dominates for accuracy.

---

## Best Performers Per Layer

| Layer | Best Mode | Best Type | Score | Accuracy | Throughput | Availability |
|-------|-----------|-----------|-------|----------|------------|--------------|
| Dense | StepTween | float32 | 379 | 42.5% | 89,116/s | 100.0% |
| **Conv2D** | **StepTweenChain** | **float32** | **1187** | **98.7%** | **120,255/s** | **100.0%** |
| RNN | StepTween | float32 | 663 | 76.5% | 86,624/s | 100.0% |
| LSTM | NormalBP | float64 | 49 | 58.5% | 5,098/s | 28.7% |
| Attention | StepTween | float32 | 830 | 90.1% | 92,099/s | 100.0% |

---

## Score Matrix: Mode Ã— Layer (float32)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Mode             â”‚ Dense      â”‚ Conv2D     â”‚ RNN        â”‚ LSTM       â”‚ Attention  â”‚ BEST LAYER        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ NormalBP         â”‚        113 â”‚        323 â”‚         65 â”‚          8 â”‚        106 â”‚ â˜… Conv2D (323)    â”‚
â”‚ StepBP           â”‚        132 â”‚        611 â”‚        139 â”‚          6 â”‚        156 â”‚ â˜… Conv2D (611)    â”‚
â”‚ Tween            â”‚        106 â”‚        398 â”‚        186 â”‚          7 â”‚        261 â”‚ â˜… Conv2D (398)    â”‚
â”‚ TweenChain       â”‚        302 â”‚        310 â”‚        169 â”‚          6 â”‚        404 â”‚ â˜… Attention (404) â”‚
â”‚ StepTween        â”‚        379 â”‚       1012 â”‚        663 â”‚         20 â”‚        830 â”‚ â˜… Conv2D (1012)   â”‚
â”‚ StepTweenChain   â”‚        299 â”‚       1187 â”‚        660 â”‚         20 â”‚        754 â”‚ â˜… Conv2D (1187)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Availability Analysis

### NormalBP vs StepTweenChain Comparison

| Layer | NormalBP Score | StepTweenChain | Winner | Accuracy Î” | Avail Î” | Throughput Î” |
|-------|----------------|----------------|--------|------------|---------|--------------|
| Dense | 113 | 299 | **StepTweenChain** | -64.4% | +63.4% | +55,983 |
| Conv2D | 323 | 1187 | **StepTweenChain** | +1.1% | +51.2% | +52,326 |
| RNN | 65 | 660 | **StepTweenChain** | -19.4% | +71.8% | +61,518 |
| LSTM | 8 | 20 | **StepTweenChain** | -39.3% | +71.3% | +8,852 |
| Attention | 106 | 754 | **StepTweenChain** | -16.3% | +62.2% | +63,386 |

> **Key Insight**: NormalBP achieves high accuracy BUT blocks inference during batch training (~30-50% availability). StepTweenChain maintains ~100% availability while still training every sample!

---

## Detailed Timeline: Conv2D + float32

### Accuracy Per Second

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Mode             â”‚ 1s  2s  3s  4s  5s  6s  7s  8s  9s  10s             â”‚ Avg   â”‚ Score    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ NormalBP         â”‚ 91% 100% 92% 100% 100% 97% 100% 96% 100% 100%       â”‚  98%  â”‚      323 â”‚
â”‚ StepBP           â”‚ 88% 100% 95% 100% 100% 98% 100% 98% 100% 100%       â”‚  98%  â”‚      611 â”‚
â”‚ Tween            â”‚ 89% 100% 92% 100% 100% 96% 100% 97% 100% 100%       â”‚  97%  â”‚      398 â”‚
â”‚ TweenChain       â”‚ 50%  95% 77%  76% 100% 37%  78% 69%  74%  78%       â”‚  73%  â”‚      310 â”‚
â”‚ StepTween        â”‚ 93% 100% 96% 100% 100% 99% 100% 99% 100% 100%       â”‚  99%  â”‚     1012 â”‚
â”‚ StepTweenChain   â”‚ 94% 100% 96% 100% 100% 98% 100% 99% 100% 100%       â”‚  99%  â”‚     1187 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Outputs Per Second (Throughput)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Mode             â”‚  1s     2s     3s     4s     5s     6s     7s     8s     9s    10s   â”‚ Total  â”‚ Avail%   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ NormalBP         â”‚ 70257  69044  68556  68313  62441  70429  68377  69656  65024  67193 â”‚ 679290 â”‚   48.8%  â”‚
â”‚ StepBP           â”‚ 64231  61955  62613  62883  63046  60503  61451  62792  63186  61675 â”‚ 624335 â”‚  100.0%  â”‚
â”‚ Tween            â”‚ 81588  73045  78791  73609  76155  72884  60999  58741  53446  62030 â”‚ 691288 â”‚   59.1%  â”‚
â”‚ TweenChain       â”‚ 68728  68956  67985  71506  70778  67773  67374  67675  69772  69502 â”‚ 690049 â”‚   61.3%  â”‚
â”‚ StepTween        â”‚ 99911 103089 101711 101449 105031 104181 101647 101959 106168 100444 â”‚1025590 â”‚  100.0%  â”‚
â”‚ StepTweenChain   â”‚120280 121466 114197 120122 121843 121253 120902 120297 121633 120561 â”‚1202554 â”‚  100.0%  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Best Numerical Type Per Layer+Mode

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Layer      â”‚ NormalBP       â”‚ StepBP         â”‚ Tween          â”‚ TweenChain     â”‚ StepTween      â”‚ StepTweenChain â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Dense      â”‚ float64   224  â”‚ uint16    141  â”‚ float32   106  â”‚ float32   302  â”‚ float32   379  â”‚ float32   299  â”‚
â”‚ Conv2D     â”‚ float64   673  â”‚ float32   611  â”‚ float32   398  â”‚ float32   310  â”‚ float32  1012  â”‚ float32  1187  â”‚
â”‚ RNN        â”‚ float64   163  â”‚ uint16    151  â”‚ float32   186  â”‚ float32   169  â”‚ float32   663  â”‚ float32   660  â”‚
â”‚ LSTM       â”‚ float64    49  â”‚ uint8      37  â”‚ int16      27  â”‚ int16      26  â”‚ int16      28  â”‚ int16      20  â”‚
â”‚ Attention  â”‚ float64   208  â”‚ float32   156  â”‚ float32   261  â”‚ float32   404  â”‚ float32   830  â”‚ float32   754  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Type Wins Summary

| Type | Wins | Visual |
|------|------|--------|
| float32 | 18 | â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ |
| float64 | 5 | â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ |
| int16 | 4 | â–ˆâ–ˆâ–ˆâ–ˆ |
| uint16 | 2 | â–ˆâ–ˆ |
| uint8 | 1 | â–ˆ |

---

## Understanding the Score Formula

```
Score = (Throughput Ã— Availability% Ã— Accuracy%) / 10000
```

This formula rewards configurations that:
1. **High Throughput**: Produce many predictions per second
2. **High Availability**: Don't block during training
3. **High Accuracy**: Make correct predictions

### Why StepTweenChain Dominates

| Factor | NormalBP | StepTweenChain | Impact |
|--------|----------|----------------|--------|
| Accuracy | ~98% | ~99% | Similar |
| Throughput | ~68k/s | ~120k/s | **+77%** |
| Availability | ~49% | 100% | **+104%** |
| **Score** | 323 | **1187** | **+267%** |

Even with similar accuracy, StepTweenChain's massive throughput and availability advantages result in a **3.7x higher score**.

---

## Conclusions

### For Real-Time Applications
Use **Conv2D + StepTweenChain + float32** for:
- Highest overall score (1187)
- 100% inference availability
- Near-perfect accuracy (98.7%)
- Maximum throughput (120k/s)

### For Maximum Accuracy (no real-time constraint)
Use **Conv2D + NormalBP + float64** for:
- Best accuracy potential
- Acceptable for batch processing
- Higher precision with float64

### LSTM Underperforms
LSTM struggles on this task because:
- The sliding window input already captures temporal context
- LSTM's recurrence adds overhead without benefit
- Simpler Conv2D pattern matching works better

---

## Running the Benchmark

```bash
cd tva/examples
go run all_sine_wave_multi.go
```

Results are saved to `all_sine_wave_multi_results.json`.
