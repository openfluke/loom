# LOOM - Deterministic Neural Virtual Machine

**"The SQLite of AI" ‚Äî A Polyglot Neural VM with Bit-Exact Reproducibility**

Loom is a **Deterministic Neural Virtual Machine (DNVM)** ‚Äî a portable execution environment for neural networks that guarantees **bitwise-identical results** across all platforms, backends, and language bindings. It combines a JIT compiler (generating WebGPU shaders at runtime) with a pure Go CPU backend to deliver the same numerical results everywhere:

*   **Portable IR:** JSON network configs are your "bytecode" ‚Äî define once, execute anywhere.
*   **JIT to GPU:** Runtime WGSL shader generation ‚Üí WebGPU compute pipelines.
*   **Polyglot FFI:** Single Go core exports to Python, C#, TypeScript, WASM via C-ABI.
*   **Bit-Exact:** 0.0000000000 difference between CPU and GPU, x86 and ARM, native and browser.

Unlike frameworks that disclaim cross-platform reproducibility, Loom **enforces determinism by design**. It compiles to a single binary with zero dependencies, transparently routing operations to CPU or WebGPU without changing user code.

[![Go Version](https://img.shields.io/badge/Go-1.24+-blue.svg)](https://golang.org)
[![License](https://img.shields.io/badge/License-Apache%202.0-green.svg)](LICENSE)
[![PyPI](https://img.shields.io/pypi/v/welvet.svg)](https://pypi.org/project/welvet/)
[![npm](https://img.shields.io/npm/v/@openfluke/welvet.svg)](https://www.npmjs.com/package/@openfluke/welvet)
[![NuGet](https://img.shields.io/nuget/v/Welvet.svg)](https://www.nuget.org/packages/Welvet/)
[![Python](https://img.shields.io/badge/Python-3.7+-blue.svg)](https://www.python.org/)
[![.NET](https://img.shields.io/badge/.NET-9.0+-512BD4.svg)](https://dotnet.microsoft.com/)

## üåç Cross-Ecosystem Compatibility

Models trained in **any platform** work instantly in all others. **Bit-for-bit identical results** across Go, Python, C#, TypeScript, and browser WASM.

| Platform | Package | Install |
|:---------|:--------|:--------|
| **Go** | [GitHub](https://github.com/openfluke/loom) | `go get github.com/openfluke/loom` |
| **Python** | [PyPI](https://pypi.org/project/welvet/) | `pip install welvet` |
| **C#/.NET** | [NuGet](https://www.nuget.org/packages/Welvet) | `dotnet add package Welvet` |
| **TypeScript/Node** | [NPM](https://www.npmjs.com/package/@openfluke/welvet) | `npm install @openfluke/welvet` |
| **Browser** | WASM | `import { init } from "@openfluke/welvet"` |

### Supported Platforms

Pre-compiled binaries for:
- **Linux**: x86_64, ARM64, ARMv7
- **Windows**: x86_64, x86, ARM64
- **macOS**: Apple Silicon (M1/M2/M3), Intel, Universal
- **Android**: ARM64, ARMv7
- **iOS**: ARM64 (XCFramework)

---

## Technical Architecture

### What is Loom?

Loom is a **Deterministic Neural Virtual Machine (DNVM)** ‚Äî a portable execution environment for neural networks that guarantees **bitwise-identical results** across all platforms, backends, and language bindings.

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                        LOOM ARCHITECTURE                                ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ   Python    ‚îÇ   ‚îÇ  TypeScript ‚îÇ   ‚îÇ     C#      ‚îÇ   ‚îÇ    WASM     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ   Binding   ‚îÇ   ‚îÇ   Binding   ‚îÇ   ‚îÇ   Binding   ‚îÇ   ‚îÇ   Browser   ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ         ‚îÇ                 ‚îÇ                 ‚îÇ                 ‚îÇ         ‚îÇ
‚îÇ         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îÇ
‚îÇ                          ‚ñº                                              ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ                        C-ABI (FFI Layer)                          ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ         Handle-based state management, JSON marshalling           ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                          ‚îÇ                                              ‚îÇ
‚îÇ                          ‚ñº                                              ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ                    EXECUTION ENGINE (nn/)                         ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ   Forward/Backward passes, Optimizers, Schedulers, Tweening       ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ         ‚îÇ                                         ‚îÇ                     ‚îÇ
‚îÇ         ‚ñº                                         ‚ñº                     ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îÇ
‚îÇ  ‚îÇ   CPU Backend   ‚îÇ                    ‚îÇ    GPU JIT Compiler     ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ   (Pure Go)     ‚îÇ                    ‚îÇ   (WGSL Generation)     ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ                 ‚îÇ                    ‚îÇ         ‚ñº               ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  Deterministic  ‚îÇ                    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  IEEE-754 Math  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫  ‚îÇ  ‚îÇ  WebGPU Runtime ‚îÇ    ‚îÇ     ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   Bit-identical    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ     ‚îÇ
‚îÇ                           results       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Classification

| Term | Description |
|:-----|:------------|
| **Virtual Machine** | Executes a portable IR (JSON network configs) on heterogeneous backends |
| **JIT Compiler** | Generates WGSL shaders at runtime, compiles to GPU compute pipelines |
| **Deterministic** | Guarantees bitwise-identical results across CPU, GPU, WASM, x86, ARM |
| **Polyglot** | Single Go core exports to Python, C#, TypeScript, WASM via C-ABI |

### Architectural Layers

| Layer | Component | Role |
|:------|:----------|:-----|
| **IR (Bytecode)** | JSON network configs, `nn/serialization.go` | Portable, declarative network specification |
| **Type System** | `nn/types.go` with `Tensor[T Numeric]` | Multi-precision tensors (F64‚ÜíI8), generic operations |
| **Execution** | `nn/forward.go`, `nn/backward.go` | Deterministic layer-by-layer forward/backward |
| **JIT Backend** | `gpu/*.go` | Runtime WGSL generation ‚Üí WebGPU pipelines |
| **FFI Runtime** | `cabi/main.go` | Handle-based API, state management, memory safety |
| **Bindings** | `python/`, `csharp/`, `typescript/`, `wasm/` | Thin wrappers exposing the C-ABI |

### Determinism Guarantee

Unlike typical ML runtimes that disclaim cross-platform reproducibility, Loom enforces **bit-exact determinism**:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Testing: Dense                                                       ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  ‚Ä¢ Max Diff:  0.0000000000 (Idx: -1)                                 ‚îÇ
‚îÇ  ‚Ä¢ Mean Diff: 0.0000000000                                           ‚îÇ
‚îÇ  ‚úÖ [GOLD STANDARD] Exact Bit-Determinism                            ‚îÇ
‚îÇ     Perfect match. CPU and GPU logic are identical down to the bit.  ‚îÇ
‚îÇ                                                                      ‚îÇ
‚îÇ  Output Sample:                                                      ‚îÇ
‚îÇ    [0] CPU: 0.5010004044 | GPU: 0.5010004044 | Diff: 0.0000000000    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Verified across:**
- CPU (Go) ‚Üî GPU (WebGPU/WGSL)
- x86_64 ‚Üî ARM64 ‚Üî ARMv7
- Linux ‚Üî Windows ‚Üî macOS ‚Üî Android ‚Üî iOS
- Native ‚Üî WASM (Browser)

### Comparison to Similar Projects

| Project | What It Is | How Loom Differs |
|:--------|:-----------|:-----------------|
| **ONNX Runtime** | Multi-backend inference engine | Loom adds *training*, *bidirectional FFI*, and *determinism guarantees* |
| **GGML** | Quantized inference library | Loom adds *GPU JIT compilation* and *cross-platform bitwise reproducibility* |
| **TVM** | Compiler infrastructure for ML | Loom is *simpler* (pure Go), *directly embeddable*, with *determinism* by design |
| **WebAssembly** | Portable bytecode standard | Loom's JSON network configs are conceptually *"WASM for neural compute"* |

### Why This Matters

1. **Reproducible Research**: Same model, same inputs ‚Üí same outputs, regardless of where it runs
2. **Cross-Platform Deployment**: Train on Linux GPU, deploy to iOS/Android/Browser with identical behavior
3. **Debugging**: No "works on my machine" issues from floating-point non-determinism
4. **Verification**: Prove correctness once, trust it everywhere

---

## Key Strengths

- **True Embeddability**: Single binary. Zero external dependencies. No Python runtime needed.
- **Hybrid Gradient/Geometric Engine**: [Neural Tweening](docs/step_tween_assessment.md) combines geometric gap-closing with backpropagation-guided momentum for real-time adaptation.
- **Geometric/Recursive Clustering**: Differentiable `KMeansLayer` allows networks to learn interpretable symbolic prototypes within a neural hierarchy.
- **Structural Parallelism**: Native support for Inception, ResNeXt, Siamese, and MoE architectures via `LayerParallel` with 6 combine modes.
- **Native Mixed-Precision**: Generic tensor backend supports `int8`, `uint16`, `float32`, `float64` natively.
- **Complete Training Infrastructure**: 7 LR schedulers, 3 optimizers (SGD/AdamW/RMSprop), 10 softmax variants.
- **Pure Go Tokenizer**: HuggingFace-compatible BPE tokenizer for LLM inference.
- **Step-Based Execution**: Real-time inference with layer-by-layer control via `StepForward` API.
- **Network Telemetry**: Runtime introspection via `GetMethodsJSON()` and `ExtractNetworkBlueprint()`.

### Key Limitations

- **Ecosystem Maturity**: No central "Model Zoo" or pip-installable convenience; relies on loading external checkpoints.
- **GPU Support**: **WebGPU** acceleration is implemented (Dense, Conv2D, MHA) but is **beta/experimental** and less stable than CuDNN/CUDA.
- **Operator Coverage**: While "Deep" support is good (MHA, LSTM), "Broad" support (e.g., 3D Conv, Deformable Attn, FFTs) is missing compared to SciPy/JAX.
- **Math Backend**: Relies on custom explicit forward/backward passes rather than a general-purpose symbolic autograd graph.

---

## Recommended Configurations

Based on exhaustive benchmarks (300+ combinations tested), here are the optimal configurations:

### Training Mode Selection

| Scenario | Recommended Mode | Why |
|:---------|:-----------------|:----|
| **Real-time / Robotics** | `StepBP` or `StepTweenChain` | 100% availability, 0ms blocking |
| **Noisy / Adversarial Data** | `StepTweenChain` | 94% robustness vs 86% for NormalBP |
| **Offline Batch Training** | `NormalBP` | Highest accuracy when blocking is acceptable |
| **Multi-Agent Systems** | `StepBP` | 12x better coordination vs blocked training |
| **Continuous Adaptation** | `StepTweenChain` | Maintains competence during distribution shift |

### Layer √ó Training Mode (float32)

| Layer | Best Mode | Score | Accuracy | Availability |
|:------|:----------|------:|:---------|:-------------|
| **Conv2D** | StepTweenChain | **1187** | 98.7% | 100% |
| **Conv2D** | StepTween | 1012 | 98.7% | 100% |
| **Attention** | StepTween | 830 | 90.1% | 100% |
| **RNN** | StepTween | 663 | 76.5% | 100% |
| **Dense** | StepTween | 379 | 42.5% | 100% |
| **LSTM** | NormalBP | 49 | 53.6% | 28.7% |

> [!TIP]
> **Conv2D + StepTweenChain + float32** is the optimal configuration for most real-time scenarios, achieving 98.7% accuracy with 100% availability.

### Numeric Type Selection

| Type | Best For | Notes |
|:-----|:---------|:------|
| **float32** | Most use cases | 18/30 benchmark wins, best accuracy |
| **float64** | Scientific computing | Higher precision, slower, wins with NormalBP |
| **int16** | LSTM layers | Only type that works for step-based LSTM |
| **uint16** | Edge/embedded | Good balance of range and speed |

> [!NOTE]
> Integer types (`int8`, `uint8`, etc.) work but achieve only ~13-23% accuracy on adaptive tasks. Use floats for training, integers for quantized inference.

---

## Benchmarks and Repro

Benchmark methodology and results live in [docs/step_tween_assessment.md](docs/step_tween_assessment.md). Results are hardware- and build-dependent; use CPU runs as the reference baseline when comparing.

---

## What's New

> üß† **Recursive Neuro-Symbolic Architecture**: The differentiable `KMeansLayer` enables models to learn hierarchical concept taxonomies. Perfect for OOD detection and robust classification. See `docs/research_paper_7_recursive_neuro_symbolic.md`.

> üéâ **Transformer Inference**: SmolLM2-135M-Instruct runs entirely in browser WASM with pure Go implementation.

> ü§Ø **Grid Softmax = Native MoE**: Mathematically proven equivalent to PyTorch MoE with 97.1% loss reduction. See `examples/moe_proof_demo.go`.

> ‚ö° **Grid Scatter Mode**: Place parallel branch outputs at specific 2D/3D grid positions for multi-agent systems, hierarchical RL, and ensemble methods with explicit topology.

> üß† **Neural Tweening**: Train and run simultaneously with 100% accuracy on shallow networks, never crashes to 0% during task changes. [Benchmarks ‚Üí](docs/step_tween_assessment.md)

> üì¶ **Recursive Safetensors**: Full support for deeply nested architectures (MoE, Sequential, Parallel) with 100% bitwise save/load consistency. Verified with `tva/testing/safetensors_recursive.go`.

> üî¢ **Numerical Type Benchmarking**: Compare network behavior across 13 numerical types (F64, F32, F16, BF16, F4, I64, I32, I16, I8, U64, U32, U16, U8) with in-memory quantization. WASM-compatible for browser deployment testing.

> üß™ **MNIST Verification**: End-to-end demo `tva/demo/conv2d-mnist/main.go` proving exact CPU/GPU consistency, training convergence, and multi-precision save/load integrity.

---

## Framework Comparison

### Global AI Landscape

| Feature Category | Feature | **Loom** (Go) | **PyTorch** (Py) | **TF / TFLite** | **GoMLX** (Go) | **Spago** (Go) | **Core ML** | **TF.js** | **Candle** (Rust) |
| :--- | :--- | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |
| **Core** | **Primary Language** | Go | Python | Python / C++ | Go | Go | Swift / ObjC | JS / TS | Rust |
| | **Runtime Dependency** | **None** (Binary) | Heavy (Pip) | Binary (Edge) | CGo / XLA | None | OS-Native | Browser | None |
| | **Auto-Differentiation** | ‚ö†Ô∏è Hybrid/Manual | ‚úÖ Full | ‚úÖ Full | ‚úÖ Full (XLA) | ‚úÖ Manual | ‚ùå (Inference) | ‚úÖ Full | ‚úÖ Full |
| | **Safetensors** | ‚úÖ **Native** | ‚úÖ | ‚úÖ | ‚úÖ | ‚ùå | ‚ùå | ‚úÖ | ‚úÖ |
| | **ONNX Support** | ‚ùå | ‚úÖ (Export) | ‚úÖ | ‚ö†Ô∏è | ‚ùå | ‚úÖ (Import) | ‚úÖ | ‚ö†Ô∏è |
| | **Structure Inference** | ‚úÖ **Auto-Detect** | ‚ùå | ‚ùå | ‚ùå | ‚ùå | ‚ùå | ‚ùå | ‚ùå |
| **Training** | **Gradient Descent** | ‚úÖ Manual Chain | ‚úÖ Standard | ‚úÖ Standard | ‚úÖ Standard | ‚úÖ Standard | ‚úÖ (On-device) | ‚úÖ Standard | ‚úÖ Standard |
| | **Neural Tweening** | ‚úÖ **Hybrid Engine** | ‚ùå | ‚ùå | ‚ùå | ‚ùå | ‚ùå | ‚ùå | ‚ùå |
| | **LR Schedulers** | ‚úÖ **7 Types** | ‚úÖ | ‚úÖ | ‚úÖ | ‚ö†Ô∏è Basic | ‚úÖ | ‚úÖ | ‚úÖ |
| | **Optimizers** | ‚úÖ **3 (SGD/AdamW/RMSprop)** | ‚úÖ Many | ‚úÖ Many | ‚úÖ | ‚úÖ | ‚ö†Ô∏è | ‚úÖ | ‚úÖ |
| **Layer Support** | **Dense (MLP)** | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ |
| | **Conv2D** | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚ùå | ‚úÖ | ‚úÖ | ‚úÖ |
| | **Conv1D** | ‚úÖ **Native** | ‚úÖ | ‚úÖ | ‚úÖ | ‚ùå | ‚úÖ | ‚úÖ | ‚úÖ |
| | **RNN / LSTM** | ‚úÖ **Full Gate** | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ |
| | **Transformer (MHA)** | ‚úÖ (Explicit) | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ (BERT) | ‚úÖ | ‚úÖ | ‚úÖ |
| | **SwiGLU** | ‚úÖ **Native** | ‚úÖ | ‚úÖ | ‚úÖ | ‚ùå | ‚ùå | ‚ùå | ‚úÖ |
| | **Parallel / MoE** | ‚úÖ **Structure** | ‚ùå (Manual) | ‚ùå (Manual) | ‚ùå | ‚ùå | ‚ùå | ‚ùå | ‚ùå |
| | **Sequential Layers** | ‚úÖ **Native** | ‚úÖ | ‚úÖ | ‚ö†Ô∏è | ‚ö†Ô∏è | ‚ö†Ô∏è | ‚úÖ | ‚ö†Ô∏è |
| | **Embeddings** | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ |
| | **Tokenizer** | ‚úÖ **Pure Go** | ‚ùå (Rust/C++) | ‚ùå (C++) | ‚ùå | ‚ùå | ‚úÖ | ‚ùå | ‚úÖ |
| **Normalization** | **LayerNorm** | ‚úÖ **Native** | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ |
| | **RMSNorm** | ‚úÖ **Native** | ‚ö†Ô∏è (Manual) | ‚ö†Ô∏è (Manual) | ‚úÖ | ‚ùå | ‚ùå | ‚ùå | ‚úÖ |
| | **Residual/Skip** | ‚úÖ **Native** | ‚úÖ | ‚úÖ | ‚úÖ | ‚ùå | ‚úÖ | ‚úÖ | ‚úÖ |
| **Advanced** | **Stitch Layers** | ‚úÖ **Native** | ‚ùå (Manual) | ‚ùå (Manual) | ‚ùå | ‚ùå | ‚ùå | ‚ùå | ‚ùå |
| | **Dynamic Arch Gen** | ‚úÖ **Built-in** | ‚ùå | ‚ùå | ‚ùå | ‚ùå | ‚ùå | ‚ùå | ‚ùå |
| | **Step-Based Forward** | ‚úÖ **Unique** | ‚ùå | ‚ùå | ‚ùå | ‚ùå | ‚ùå | ‚ùå | ‚ùå |
| | **K-Means Clustering** | ‚úÖ **Differentiable** | ‚ùå | ‚ùå | ‚ùå | ‚ùå | ‚ùå | ‚ùå | ‚ùå |
| | **Correlation Analysis** | ‚úÖ **Pearson/Spearman** | ‚ùå | ‚ùå | ‚ùå | ‚ùå | ‚ùå | ‚ùå | ‚ùå |
| | **Model Evaluation** | ‚úÖ **Deviation/Metrics** | ‚úÖ | ‚úÖ | ‚ö†Ô∏è | ‚ö†Ô∏è | ‚ö†Ô∏è | ‚ö†Ô∏è | ‚ö†Ô∏è |
| | **Network Telemetry** | ‚úÖ **Blueprint API** | ‚ùå | ‚ö†Ô∏è | ‚ùå | ‚ùå | ‚ùå | ‚ö†Ô∏è | ‚ùå |
| | **Runtime Introspection** | ‚úÖ **Reflection** | ‚ö†Ô∏è (Python) | ‚ö†Ô∏è | ‚ùå | ‚ùå | ‚ùå | ‚ö†Ô∏è | ‚ùå |
| **Platform** | **WASM Training** | ‚úÖ **Full** | ‚ùå | ‚ùå | ‚ùå | ‚ùå | ‚ùå | ‚úÖ (Slow) | ‚úÖ |
| | **Cross-Lang ABI** | ‚úÖ **Universal** | ‚ùå | ‚ùå | ‚ùå | ‚ùå | ‚ùå | ‚ùå | ‚ö†Ô∏è |
| **Ecosystem** | **HuggingFace Hub** | ‚ö†Ô∏è (Read/Inspect) | ‚úÖ Native | ‚úÖ Native | ‚ùå | ‚úÖ | ‚ùå | ‚úÖ | ‚úÖ |
| | **Pre-trained Zoo** | ‚ùå | ‚úÖ Massive | ‚úÖ Massive | ‚ùå | ‚úÖ (Small) | ‚úÖ (Apple) | ‚úÖ Large | ‚ö†Ô∏è Growing |
| | **Mobile/Web** | ‚úÖ **WASM / C-ABI** | ‚úÖ (Mobile) | ‚úÖ **King** | ‚ùå | ‚ùå | ‚úÖ **King (iOS)** | ‚úÖ **King (Web)** | ‚úÖ (WASM) |

### Go Ecosystem Comparison

| **Category** | **Feature** | **Loom** | **GoMLX** | **Gorgonia** | **Spago** | **Go-Deep** | **Gonum** |
| :--- | :--- | :---: | :---: | :---: | :---: | :---: | :---: |
| **Foundation** | **Primary implementation** | Pure Go | CGo (XLA) | Pure Go + CGo | Pure Go | Pure Go | Pure Go |
| | **Tensor Backend** | Custom (Generic) | XLA (C++) | Custom | Custom (Dense) | Custom | Dense Matrix |
| | **Autograd** | ‚ö†Ô∏è Hybrid | ‚úÖ Full | ‚úÖ Symbolic | ‚úÖ Dynamic | ‚úÖ Backprop | ‚ùå |
| **Model** | **Load Safetensors** | ‚úÖ **Native** | ‚úÖ | ‚ùå | ‚ùå | ‚ùå | ‚ùå |
| | **Model Export** | binary/json | XLA format | Onnx (Import) | Gob | Json | ‚ùå |
| **Architecture** | **Dense (MLP)** | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ (Matrix Mul) |
| | **Conv2D** | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚ùå |
| | **Conv1D** | ‚úÖ **Native** | ‚úÖ | ‚ö†Ô∏è (via 2D) | ‚ö†Ô∏è (via 2D) | ‚ùå | ‚ùå |
| | **RNN / LSTM** | ‚úÖ **Full Gate** | ‚úÖ | ‚ö†Ô∏è Basic | ‚úÖ BiLSTM | ‚ùå | ‚ùå |
| | **Transformer (MHA)** | ‚úÖ **Explicit** | ‚úÖ | ‚ö†Ô∏è Hard | ‚úÖ (BERT) | ‚ùå | ‚ùå |
| | **SwiGLU** | ‚úÖ | ‚úÖ | ‚ùå | ‚ùå | ‚ùå | ‚ùå |
| | **Embeddings** | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚ùå | ‚ùå |
| | **Parallel / MoE** | ‚úÖ **MoE + Gating** | ‚ùå (Manual) | ‚ùå | ‚ùå | ‚ùå | ‚ùå |
| | **Sequential Layers** | ‚úÖ **Native + Nested** | ‚ö†Ô∏è (Manual) | ‚ö†Ô∏è (Manual) | ‚ö†Ô∏è (Manual) | ‚ùå | ‚ùå |
| | **Tokenizer** | ‚úÖ **Pure Go** | ‚ùå (Deps) | ‚ùå | ‚úÖ (WordPiece) | ‚ùå | ‚ùå |
| **Training** | **Gradient Descent** | ‚úÖ Manual | ‚úÖ Standard | ‚úÖ Standard | ‚úÖ Standard | ‚úÖ Standard | ‚ùå |
| | **Hybrid Tweening** | ‚úÖ **Unique** | ‚ùå | ‚ùå | ‚ùå | ‚ùå | ‚ùå |
| | **LR Schedulers** | ‚úÖ **7 Types** | ‚úÖ | ‚úÖ | ‚ö†Ô∏è Basic | ‚ùå | ‚ùå |
| | **Optimizers** | ‚úÖ **SGD/AdamW/RMSprop** | ‚úÖ | ‚úÖ | ‚úÖ | ‚ö†Ô∏è SGD | ‚ùå |
| | **Softmax Variants** | ‚úÖ **10 Types** | ‚ö†Ô∏è Standard | ‚ö†Ô∏è Standard | ‚ö†Ô∏è Standard | ‚ö†Ô∏è Standard | ‚ùå |
| **Normalization** | **LayerNorm** | ‚úÖ **Native** | ‚úÖ | ‚ö†Ô∏è Manual | ‚úÖ | ‚ùå | ‚ùå |
| | **RMSNorm** | ‚úÖ **Native** | ‚úÖ | ‚ùå | ‚ùå | ‚ùå | ‚ùå |
| | **Residual/Skip** | ‚úÖ **Native** | ‚úÖ | ‚úÖ | ‚ùå | ‚ùå | ‚ùå |
| **Advanced** | **RoPE Embeddings** | ‚úÖ **GQA Support** | ‚úÖ | ‚ùå | ‚ùå | ‚ùå | ‚ùå |
| | **Network Grafting** | ‚úÖ **Unique** | ‚ùå | ‚ùå | ‚ùå | ‚ùå | ‚ùå |
| | **Step-Based Forward** | ‚úÖ **Unique** | ‚ùå | ‚ùå | ‚ùå | ‚ùå | ‚ùå |
| | **Dynamic Arch Gen** | ‚úÖ **Unique** | ‚ùå | ‚ùå | ‚ùå | ‚ùå | ‚ùå |
| | **K-Means Clustering** | ‚úÖ **Differentiable** | ‚ùå | ‚ùå | ‚ùå | ‚ùå | ‚ùå |
| | **Correlation Analysis** | ‚úÖ **Pearson/Spearman** | ‚ùå | ‚ùå | ‚ùå | ‚ùå | ‚ùå |
| | **Model Evaluation** | ‚úÖ **Full Suite** | ‚ö†Ô∏è | ‚ö†Ô∏è | ‚ö†Ô∏è | ‚ùå | ‚ùå |
| | **Network Telemetry** | ‚úÖ **Blueprint** | ‚ùå | ‚ö†Ô∏è | ‚ùå | ‚ùå | ‚ùå |
| | **Runtime Introspection** | ‚úÖ **Reflection** | ‚ùå | ‚ö†Ô∏è | ‚ùå | ‚ùå | ‚ùå |
| **Platform** | **C-ABI (Polyglot)** | ‚úÖ **Universal** | ‚ùå | ‚ùå | ‚ùå | ‚ùå | ‚ùå |
| | **WASM Training** | ‚úÖ **Full** | ‚ùå (XLA) | ‚ùå | ‚ùå | ‚ùå | ‚ùå |
| **Ecosystem** | **HuggingFace** | ‚ö†Ô∏è (Load) | ‚ùå | ‚ùå | ‚úÖ (Load) | ‚ùå | ‚ùå |
| | **Documentation** | ‚ö†Ô∏è Growing | ‚úÖ Good | ‚úÖ Good | ‚úÖ Good | ‚ö†Ô∏è Minimal | ‚úÖ Excellent |
| | **Maintenance** | üî• Active | üî• Active | ‚ö†Ô∏è Slow | ‚è∏Ô∏è Paused | ‚ö†Ô∏è Slow | üî• Active |

### Native Numerical Type & Precision Support

| **Layer Type** | **Numerical Type** | **Loom** | **GoMLX** | **Gorgonia** | **Spago** | **PyTorch** |
| :--- | :--- | :---: | :---: | :---: | :---: | :---: |
| **All Layers** | **Float32** | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ (Float64) | ‚úÖ |
| (Dense, Conv, | **Float64 (High Prec)** | ‚úÖ **Native** | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ |
| RNN, Attn) | **Float16 / BF16** | ‚ö†Ô∏è (Storage) | ‚úÖ (XLA) | ‚ùå | ‚ùå | ‚úÖ |
| | **Int8 (Training)** | ‚úÖ **Native** | ‚ùå | ‚ùå | ‚ùå | ‚ö†Ô∏è (QAT Wrapper) |
| | **Int8 (Inference)** | ‚úÖ | ‚ùå | ‚ùå | ‚ùå | ‚úÖ (Quant) |
| | **Int16, Int32, Int64** | ‚úÖ **Native** | ‚úÖ (XLA) | ‚ö†Ô∏è (Tensor) | ‚ùå | ‚ùå (Tensor Only) |
| | **Uint8, Uint16, Uint32** | ‚úÖ **Native** | ‚úÖ (XLA) | ‚ö†Ô∏è (Tensor) | ‚ùå | ‚úÖ (Uint8 Only) |

> [!NOTE]
> **Complete Type System**: Unlike frameworks that treat integers primarily as storage formats for quantization, Loom's Generics allow **native training and inference** on exotic types like `uint16` (common in medical imaging), `int32`, or `float64` (scientific sim) across **every layer type** without changes to the model code.

### Summary Verdict

- **Choose PyTorch** if you are doing **Research**, need the latest SOTA models, or rely on complex dynamic architectures.
- **Choose TensorFlow / TFLite** if you need robust **Mobile/Edge Deployment**.
- **Choose GoMLX** if you need **High-Performance Training in Go** and can tolerate CGo/C++ dependencies.
- **Choose Core ML** if you are targeting **iOS/macOS** exclusively.
- **Choose Loom** if you need **Pure Go-Native Embedding** (Cloud/CLI/Server), want a single binary with zero dependencies, need to experiment with the **Neural Tweening** training paradigm, or need unique features like **Step-Based Forward Pass** for real-time inference and **Dynamic Architecture Generation** for automated model exploration.

---

## Layer Types & Features

### Supported Layer Types

| Layer | Type String | Description |
|:------|:------------|:------------|
| Dense | `dense` | Fully connected layer |
| LSTM | `lstm` | Long Short-Term Memory |
| RNN | `rnn` | Recurrent Neural Network |
| GRU | `gru` | Gated Recurrent Unit |
| Conv2D | `conv2d` | 2D Convolution |
| Conv1D | `conv1d` | 1D Convolution |
| Multi-Head Attention | `multi_head_attention` | Transformer attention |
| LayerNorm | `layer_norm` | Layer normalization |
| RMSNorm | `rms_norm` | RMS normalization |
| SwiGLU | `swiglu` | SwiGLU activation layer |
| KMeans | `kmeans` | Differentiable recursive clustering layer |
| Softmax | `softmax` | 10 variants (Standard, Grid, Hierarchical, Temperature, Gumbel, Masked, Sparsemax, Entmax, Adaptive, Mixture) |
| Embedding | `embedding` | Token embedding |
| Parallel | `parallel` | Branching with 6 combine modes (add, concat, multiply, average, grid_scatter, filter) |
| Sequential | `sequential` | Grouped sub-layers |

### Activation Functions

`relu`, `sigmoid`, `tanh`, `softmax`, `gelu`, `swish`, `mish`, `leaky_relu`, `elu`, `selu`, `linear`

---

## SafeTensors & Model Interoperability
 
Loom features a **universal SafeTensors engine** capable of standardizing models from any framework (PyTorch, TensorFlow, HuggingFace) into a highly optimized, single-file format. It proactively handles complex **nested architectures** (like Mixture-of-Experts within Parallel layers) via recursive serialization.
 
### 1. Universal "Any-to-Any" Quantization
Load a model in high precision (`float32`/`float64`) and instantly quantize it to any supported type for deployment. The file format handles the type conversion automatically.
 
- **Input**: Model weights in `F32` (e.g., from HuggingFace)
- **Output**: Quantized weights in `F4`, `I8`, `BF16`, `U16` etc.
- **Verification**: 100% round-trip integrity verified for all 143 layer/type combinations.
 
```go
// Load standard model
tensors, _ := nn.LoadSafetensors("llama.safetensors")
 
// Save as 4-bit optimized web model (automatically quantizes)
for name, t := range tensors { t.DType = "F4" }
nn.SaveSafetensors("llama-web-4bit.safetensors", tensors)
```
 
### 2. WASM / In-Memory Operation
Loom's SafeTensors implementation can operate **purely in memory** (using `[]byte` buffers) without any filesystem access, making it perfect for **WebAssembly (WASM)** and constrained environments.
 
```go
// Serialize directly to memory (for sending to browser/client)
bytes, _ := nn.SerializeSafetensors(myModelWeights)
 
// Load directly from memory (no disk I/O required)
tensors, _ := nn.LoadSafetensorsWithShapes(bytes)
```
 
### 3. Full Layer Support
The interoperability layer supports every component in the Loom ecosystem:
 
| Category | Supported Layers | 
|:---|:---|
| **Core** | `Dense`, `Embedding`, `Parallel`, `Sequential` |
| ** Convolution** | `Conv1D`, `Conv2D` |
| **Sequence** | `RNN`, `LSTM`, `GRU` |
| **Attention** | `MultiHeadAttention`, `SwiGLU` |
| **Norm/Act** | `LayerNorm`, `RMSNorm`, `Softmax` (10 variants) |
 
---
 
## GPU Acceleration (WebGPU)

**Experimental** GPU acceleration via WebGPU compute shaders. Treat all GPU paths (forward and backward) as experimental for now. Use with:

```go
network.GPU = true
network.WeightsToGPU()           // Mount weights to GPU
output, _ := network.Forward(input)  // Auto-routes to GPU!
network.Backward(dOutput)     // GPU backward pass
network.ReleaseGPUWeights()      // Cleanup
```

### GPU Support Matrix

| Layer Type | Forward | Backward (Training) | Notes |
|:-----------|:-------:|:-------------------:|:------|
| **Dense** | ‚úÖ **Stable** | ‚ö†Ô∏è **Experimental** | Production speedup (20x) on large layers. |
| **Conv2D** | ‚úÖ **Stable** | ‚ö†Ô∏è **Experimental** | Works well, optimized for 32+ filters. |
| **Conv1D** | ‚úÖ **Stable** | ‚ö†Ô∏è **Experimental** | Gradients implemented, accuracy tuning needed. |
| **RNN** | ‚úÖ **Stable** | ‚ö†Ô∏è **Experimental** | Weights update, but BPTT limited to batch=1. |
| **LSTM** | ‚úÖ **Stable** | ‚ö†Ô∏è **Experimental** | Same limitations as RNN. |
| **LayerNorm** | ‚úÖ **Stable** | ‚ö†Ô∏è **Experimental** | Forward is stable, backward can be numeric unstable. |
| **RMSNorm** | ‚úÖ **Stable** | ‚ö†Ô∏è **Experimental** | Same as LayerNorm. |
| **SwiGLU** | ‚úÖ **Stable** | ‚ö†Ô∏è **Experimental** | High performance. |
| **MHA** | ‚úÖ **Stable** | ‚ö†Ô∏è **Experimental** | Functional parity verified. |
| **Softmax** | ‚úÖ **Stable** | ‚ö†Ô∏è **Experimental** | Functional. |
| **KMeans** | ‚ùå **WIP** | ‚ùå **WIP** | Currently runs on CPU only. |


## Quick Start

Quick docs:
- [NN Overview](docs/nn/overview.md)
- [NN Quick Reference](docs/nn/quick_reference.md)

### Installation

```bash
# Clone the repository
git clone https://github.com/openfluke/loom.git
cd loom

# Install dependencies
go mod download
```

### Simple Example

```go
package main

import (
    "fmt"
    "github.com/openfluke/loom/nn"
)

func main() {
    network := nn.NewNetwork(4096, 4, 4, 5)  // 80 total layers

    if err := network.InitGPU(); err != nil {
        panic(err)
    }
    defer network.ReleaseGPU()

    input := make([]float32, 4096)
    output, gpuTime, _ := network.ForwardGPU(input)

    fmt.Printf("GPU Forward time: %v, Output size: %d\n", gpuTime, len(output))
}
```

### Model Serialization

```go
// Save a trained model
err := network.SaveModel("model.json", "my_model")

// Load it back - ONE LINE!
loadedNet, err := nn.LoadModel("model.json", "my_model")

// Or use strings (great for APIs/databases/WASM)
jsonString, err := network.SaveModelToString("my_model")
loadedNet, err := nn.LoadModelFromString(jsonString, "my_model")
```

### Cross-Platform API

| Function | Go | Python | TypeScript | C# | C |
|:---------|:---|:-------|:-----------|:---|:--|
| Create | `BuildNetworkFromJSON()` | `create_network_from_json()` | `createNetworkFromJSON()` | `CreateLoomNetwork()` | `CreateLoomNetwork()` |
| Forward | `Forward()` | `forward_simple()` | `forward()` | `LoomForward()` | `LoomForward()` |
| Train | `Train()` | `train_simple()` | `train()` | `LoomTrain()` | `LoomTrain()` |
| Save | `SaveModelToString()` | `save_model_simple()` | `saveModel()` | `LoomSaveModel()` | `LoomSaveModel()` |
| Load | `LoadModelFromString()` | `load_model_simple()` | `loadLoomNetwork()` | `LoomLoadModel()` | `LoomLoadModel()` |
| Evaluate | `EvaluateNetwork()` | `evaluate_network_simple()` | `evaluate()` | `LoomEvaluateNetwork()` | `LoomEvaluateNetwork()` |

---

## Language Bindings

### Python

```bash
pip install welvet
```

```python
import welvet

config = {"batch_size": 1, "layers": [...]}
welvet.create_network_from_json(config)
output = welvet.forward_simple([0.1, 0.2, 0.3, 0.4])
```

See [python/README.md](python/README.md) for complete documentation.

### TypeScript / Node.js

```bash
npm install @openfluke/welvet
```

```typescript
import { init, createNetworkFromJSON } from "@openfluke/welvet";

await init();
const network = createNetworkFromJSON(JSON.stringify(config));
const output = network.Forward(JSON.stringify([[0.1, 0.2, 0.3, 0.4]]));
```

See [typescript/README.md](typescript/README.md) for complete documentation.

### C# / .NET

```bash
dotnet add package Welvet
```

```csharp
using Welvet;

Network.CreateFromJson(config);
var output = NativeMethods.LoomForward(input, input.Length);
```

See [csharp/README.md](csharp/README.md) for complete documentation.

---

## Project Structure

```
loom/
‚îú‚îÄ‚îÄ nn/                  # Neural network package (core)
‚îú‚îÄ‚îÄ tokenizer/           # Pure Go BPE tokenizer
‚îú‚îÄ‚îÄ wasm/                # WebAssembly module
‚îú‚îÄ‚îÄ cabi/                # C ABI for FFI
‚îú‚îÄ‚îÄ python/              # Python package (welvet)
‚îú‚îÄ‚îÄ typescript/          # TypeScript/WASM package
‚îú‚îÄ‚îÄ csharp/              # C#/.NET package (Welvet)
‚îú‚îÄ‚îÄ fabric/              # Demo application
‚îú‚îÄ‚îÄ pods/                # GPU compute pods
‚îú‚îÄ‚îÄ model_conversion/    # HuggingFace model import
‚îú‚îÄ‚îÄ docs/                # Documentation
‚îî‚îÄ‚îÄ detector/            # GPU device detection
```

---

## Documentation

- [Neural Network Package](nn/README.md) - Detailed API documentation
- [Neural Tweening Benchmarks](docs/step_tween_assessment.md) - 19-test comprehensive benchmark
- [Evaluation & Metrics](docs/nn/evaluation.md) - Deviation metrics, numerical type benchmarking, WASM-compatible verification
- [Python Bindings](python/README.md) - PyPI package docs
- [TypeScript Bindings](typescript/README.md) - NPM package docs
- [C# Bindings](csharp/README.md) - NuGet package docs
- [WASM Module](wasm/README.md) - Browser deployment
- [C ABI](cabi/README.md) - FFI reference
- [Model Conversion](model_conversion/README.md) - HuggingFace import guide

**More Examples:** See [github.com/openfluke/tva](https://github.com/openfluke/tva) for additional examples and experiments.

## Comprehensive Test Suite

Loom includes a rigorous verification suite in `tva/muniversal_testing.go` that validates functional correctness across all layers, numeric types, and backend engines (CPU/GPU).

### Coverage Summary

| Test Section | Description | Status |
|:-------------|:------------|:-------|
| **Part 1: Core** | Forward/backward pass correctness for basic layers | ‚úÖ Covered |
| **Part 2: Serialization** | Save/Load permutations for all layers and types (`float32`, `int8`, `uint16`, etc.) | ‚úÖ Covered |
| **Part 3: Advanced** | Complex layers (MHA, Grid Softmax, K-Means) and math ops | ‚úÖ Covered |
| **Part 5: GPU Determinism** | Validates GPU forward pass matches CPU results | ‚úÖ Covered |
| **Part 6: GPU Training** | Verifies GPU learning convergence vs CPU baseline | ‚úÖ Covered |

> [!NOTE]
> **GPU Acceleration Limits:** As of v0.0.8, WebGPU acceleration is enabled for standard `Forward/Backward` passes. 
> The structural API `nn/step_forward.go` (Step-based execution), `nn/tween.go` (Neural Tweening), and `nn/kmeans_layer.go` (K-Means) currently run on **CPU only**.

### Verified Advanced Architectures

The test suite also verifies complex, production-ready architectural patterns:

- **Recursive Symbol Learning (RN1-RN6)**: Differentiable K-Means layers nested to form taxonomies, achieving 100% accuracy on hierarchical tasks with full interpretability.
- **Heterogenous MoE**: Using `LayerParallel` with `CombineMode: "filter"` to route inputs to experts of different depths/types (e.g., CNN expert vs Dense expert).
- **Stitched Experts**: Using `LayerStitch` to harmonize outputs from parallel branches with different dimensions (e.g., 5-dim output and 7-dim output stitched to common 10-dim).
- **Neural Grafting**: Training *only* the gating mechanism of an MoE while keeping experts frozen, using `TweenStep` for precise surgical updates.
- **Bit-Exact Determinism**: Verifying that GPU forward passes match CPU results to within machine epsilon (often exactly bit-matching for integer ops).

### Runnable Demos

- **MNIST Consistency (`tva/demo/conv2d-mnist/main.go`)**:
  - Trains a digit classifier on MNIST.
  - Saves model to JSON and Safetensors.
  - Reloads model and verifies **0.000000000 max difference** in predictions.
  - Benchmarks all 13 numerical types (F64‚ÜíU8) for quantization quality.
  - Proves robustness of `SaveWeightsToSafetensors` / `LoadWeightsFromSafetensors`.

- **Recursive Safetensors (`tva/testing/safetensors_recursive.go`)**:
  - Constructs a complex nested Network: `MoE (Gate) -> [Parallel -> [Dense, Sequential -> [Conv1D, RNN]]]`.
  - Saves and reloads to prove structural integrity of serialization for arbitrary depths.


---

## Requirements

- **Go**: 1.24 or higher
- **GPU**: WebGPU-compatible GPU (Vulkan, Metal, or D3D12) - *optional*
- **OS**: Linux, macOS, or Windows

---

## Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## License

Apache License 2.0 - see [LICENSE](LICENSE) file for details.

---

**Made with ‚ù§Ô∏è by Openfluke**
